{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13240090-8e81-46dc-a224-3eb12e5e5df5",
   "metadata": {},
   "source": [
    "<h1> Assignment 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6671ba4-6d13-430e-92cb-d39368974845",
   "metadata": {},
   "source": [
    "<h1> Name & Z-ID \n",
    "<h3> Daniel Bendik\n",
    "<h3> z1938845\n",
    "<h3> CSCI 490\n",
    "<h3> Dr. Maoyuan Sun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57cceca-d00e-457e-990d-b26045db0498",
   "metadata": {},
   "source": [
    "<h1> Download & Extract Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "832f34ae-226f-4ed2-89a3-52efd740e440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 120_million_to_199_million.zip\n",
      "Downloaded 80_million_to_99_million.zip\n",
      "Downloaded 100_million_to_119_million.zip\n",
      "Downloaded 75_million_to_79_million.zip\n",
      "Downloaded 250_million_to_999_million.zip\n",
      "Downloaded 200_million_to_249_million.zip\n"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "async def download_file(url, filename):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(url) as response:\n",
    "            with open(filename, 'wb') as f:\n",
    "                while True:\n",
    "                    chunk = await response.content.read(1024)\n",
    "                    if not chunk:\n",
    "                        break\n",
    "                    f.write(chunk)\n",
    "    print(f'Downloaded {filename}')\n",
    "\n",
    "async def download_all_files():\n",
    "    file_url = 'https://faculty.cs.niu.edu/~smaoyuan/courses/csci503/a7/'\n",
    "    ranges = [(75,79), (80,99), (100,119), (120,199), (200,249), (250,999)]\n",
    "\n",
    "    tasks = []\n",
    "\n",
    "    for start, end in ranges:\n",
    "        filename = f'{start}_million_to_{end}_million.zip'\n",
    "        url = f'{file_url}{filename}'\n",
    "        tasks.append(asyncio.create_task(download_file(url, filename)))\n",
    "\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "async def extract_zip_files():\n",
    "    zip_files = [f for f in os.listdir() if f.endswith('.zip')]\n",
    "    extract_dir = 'artist-data'\n",
    "    Path(extract_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for file in zip_files:\n",
    "        with zipfile.ZipFile(file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_dir)\n",
    "\n",
    "async def main():\n",
    "    await download_all_files()\n",
    "    await extract_zip_files()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if asyncio.get_event_loop().is_running():\n",
    "        await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70cfeeb-91bf-4bd9-bec3-3e0996ccb161",
   "metadata": {},
   "source": [
    "<h1> Find Matching Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9fca26e-671a-423c-8780-3958bc8b26d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 artist-data/75_million_to_79_million/United States/kenny-g.npy\n",
      "2 artist-data/75_million_to_79_million/United States/alabama.npy\n",
      "3 artist-data/75_million_to_79_million/United States/luke-bryan.npy\n",
      "4 artist-data/75_million_to_79_million/United States/imagine-dragons.npy\n",
      "5 artist-data/75_million_to_79_million/United States/gloria-estefan.npy\n",
      "6 artist-data/75_million_to_79_million/Other/the-weeknd.npy\n",
      "7 artist-data/100_million_to_119_million/United States/george-strait.npy\n",
      "8 artist-data/100_million_to_119_million/United States/janet-jackson.npy\n",
      "9 artist-data/100_million_to_119_million/United Kingdom/george-michael.npy\n",
      "10 artist-data/100_million_to_119_million/Other/nicki-minaj.npy\n",
      "11 artist-data/80_million_to_99_million/United States/lionel-richie.npy\n",
      "12 artist-data/80_million_to_99_million/United States/post-malone.npy\n",
      "13 artist-data/80_million_to_99_million/United States/ariana-grande.npy\n",
      "14 artist-data/80_million_to_99_million/United States/flo-rida.npy\n",
      "15 artist-data/80_million_to_99_million/United States/r.e.m..npy\n",
      "16 artist-data/250_million_to_999_million/United States/madonna.npy\n",
      "17 artist-data/250_million_to_999_million/Other/rihanna.npy\n",
      "18 artist-data/200_million_to_249_million/United States/taylor-swift.npy\n",
      "19 artist-data/200_million_to_249_million/United States/whitney-houston.npy\n",
      "20 artist-data/200_million_to_249_million/Other/celine-dion.npy\n",
      "21 artist-data/120_million_to_199_million/United States/bruno-mars.npy\n",
      "22 artist-data/120_million_to_199_million/United States/katy-perry.npy\n",
      "23 artist-data/120_million_to_199_million/United States/metallica.npy\n",
      "24 artist-data/120_million_to_199_million/United States/lady-gaga.npy\n",
      "25 artist-data/120_million_to_199_million/United States/bon-jovi.npy\n",
      "26 artist-data/120_million_to_199_million/United States/chris-brown.npy\n",
      "27 artist-data/120_million_to_199_million/United Kingdom/adele.npy\n",
      "28 artist-data/120_million_to_199_million/United Kingdom/ed-sheeran.npy\n",
      "29 artist-data/120_million_to_199_million/United Kingdom/phil-collins.npy\n",
      "30 artist-data/120_million_to_199_million/Other/drake.npy\n",
      "31 artist-data/120_million_to_199_million/Other/u2.npy\n",
      "32 artist-data/120_million_to_199_million/Other/justin-bieber.npy\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def get_files(directory):\n",
    "    npy_files = []\n",
    "    for file in Path(directory).rglob('*.npy'):\n",
    "        npy_files.append(file)\n",
    "    return npy_files\n",
    "\n",
    "npy_files = get_files('artist-data')\n",
    "\n",
    "x = 1\n",
    "for file in npy_files:  # Print the paths to each file\n",
    "    print(x, file)\n",
    "    x+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070c99d5-1997-4cae-8b18-095b41b25160",
   "metadata": {},
   "source": [
    "<h1> Use Threads to Process Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a79f75e-21a4-4023-9c2d-c7882c52f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "\n",
    "def get_files(directory):  # Reused function from Part 2 \"Find Matching Files\"\n",
    "    npy_files = []\n",
    "    for file in Path(directory).rglob('*.npy'):\n",
    "        npy_files.append(file)\n",
    "    return npy_files\n",
    "\n",
    "def process_npy_file(file_path):\n",
    "    # Convert the Numpy array to dataframe\n",
    "    arr = np.load(file_path)\n",
    "    df = pd.DataFrame({'Date': arr[0], 'Views': arr[1]})\n",
    "\n",
    "    # Convert the filename into the artist's name\n",
    "    artist_name = file_path.stem.replace('-', ' ').title()\n",
    "    df['Artist'] = artist_name\n",
    "    return df\n",
    "\n",
    "async def main():\n",
    "    npy_files = get_files('artist-data')\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        dfs = list(executor.map(process_npy_file, npy_files))\n",
    "\n",
    "    # Concatenate dataframes\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Split the combined dataframes into monthly dataframes\n",
    "    for month, month_df in combined_df.groupby(combined_df['Date']):\n",
    "        output_filename = f'{month}.csv.gz'\n",
    "        month_df.to_csv(output_filename, index=False, compression='gzip')  # Save them as .csv.gz files\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if asyncio.get_event_loop().is_running():  # Do this since we're using JupyterLab\n",
    "        await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b03edc-ec66-486d-9523-ec68c9ba85ad",
   "metadata": {},
   "source": [
    "<h2> ^ This takes about 10 seconds to finish executing ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5729964-5661-4b29-b3d2-b9bde58b175d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
